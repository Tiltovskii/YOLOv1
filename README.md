# YOLOv1
**Implementation of YOLOv1**

Что за YOLOv1?
------------------------------------

YOLO - это популярная one-shot модель детекции объектов на изображении.  YOLOv1 - это первая версия модели, которая была разработана в 2016 году. На данный момент уже выпущена YOLOv4.

В репозитории есть `.py` файлы, в которых есть реализации оснвоных функций: `YOLO Loss`, `Модель Yolo`, `Non-maximum supression`, `Mean-average precision` и т.д.

Дальше я хочу пояснить за основные функции, модель и лосс, чтоб людям было понятнее, откуда и что берется.

Модель Yolo
------------------------------------

Модели поступает на вход 3-х канальное изображение с высотой и широтой 448 на 448. По средствам сверточных и полносвязных слоев, реализованных полностью с оригинальной статьи по [YOLO](https://arxiv.org/pdf/1506.02640.pdf), на выходе мы получаем тензор с размерами S*S*(5*B+C), где

* S*S - размер кол-во клеток, разбивающих исходное изображение, в которых будут предсказываться боксы и классы.
* B - это кол-во боксов, предсказанных в одной такой клетке. Пятерка стоящая перед B показывает, что каждая клетка должная иметь 4 координаты задающие прямоугольник и еще значение уверенности в том, что внутри прямоугольника есть объект.
* C - это кол-во классов в датасете.

YOLO Loss
------------------------------------

`Yolo Loss` разбит на две основные части:

1) Если у нас бокс предсказывает объект в клетке, где действительно есть объект, то есть наш таргет бокс, то у нас лосс принимает бокс с наибольшей уверенностью в этой клетке и считает сумму квадратичных ошибок координат центров, корней широт, уверенности и пересечения предсказанного бокса и таргет бокса (IoU), классов.

2) Если у нас бокс предсказывает объект в клетке, где нет объекта (таргет бокса), то у нас считается квадратичная ошибка уверенностей боксов с нулем.

Конечно, еще нужно упомянуть, что так как у нас мало объектов, а боксов предсказанных много, то модели может станет выгодно занулять уверенности, ведь их часто просят быть около нуля, поэтому перед уверенностями в лоссе добавляют $\lambda_{obj}$ и $\lambda_{noobj}$, где $\lambda_{obj}$ должен быть больше на порядок, чем $\lambda_{noobj}$.

Non-maximum supression
------------------------------------

Эта функция, использующаяся на инференся, когда у нас могут несколько боксов предсказывать один объект и сильно перекрываться между собой. Вот эти перекрывающиеся боксы мы и убераем. Так же тут убираются боксы с маленькими уверенностями.
![image](https://user-images.githubusercontent.com/90857881/209959588-bfa6c78e-36fd-4e42-8ea7-9a1607b759d9.png)

Mean-average precision
------------------------------------

Эта функция считает основную метрику для задачи детекции, которая заключается в том, что мы считаем PR-AUC для каждого класса и потом вычисляем их среднее. В файле `Utils.py` об этом рассказано подробнее.

Итог
------------------------------------
В файле `Baseline.ipynb` есть весь код от обработки датасета до обучения итоговой модели и просмотра её результата. В других файлах собраны все функции и классы, написанные в `Baseline.ipynb`, для удобства их поиска, если нужна реализация конкретно чего-то. 
